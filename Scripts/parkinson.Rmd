---
title: "PARKINSON DATASET"
author: "JOSÉ LUIS"
date: "2024-10-08"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlights: espresso
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, comment = NA)
```

# CÓDIGO {.tabset}

Este documento contiene un preprocesamiento de datos inicial que permite un buen estudio exploratorio EDA. Luego, contiene un preprocesamiento más avanzado que permite la creación de varios modelos que expliquen bien la variable objetivo (status) para poder evaluarlo a través de validación cruzada. 

## LIBRERIAS
```{r}
# All these libraries may not be used in the chunks. It's just a standar libraries i always use just to not have to search for them in case i need them.
library(caret)
library(ConfusionTableR)
library(DataExplorer)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(kableExtra)
library(ModelMetrics)
library(openxlsx)
library(plotly)
library(probably)
library(pROC)
library(psych)
library(purrr)
library(randomForest)
library(reshape2)
library(skimr)
library(stringr)
library(tidymodels)
library(tidyverse)
library(univariateML)
library(vip)
library(xgboost)
library(WRS2)
library(GGally)
library(lmtest)
library(e1071)
library(fastDummies)
library(class)
library(ROCR)
library(corrplot)
```


## PREPROCESAMIENTO INICIAL {.tabset}

OBSERVAMOS NUESTRO DATASET SIN NINGUNA MODIFICACIÓN

### DATASET Y VARIABLES
```{r}
# Primero observamos un poco el dataset
data = read.csv("parkinsons.csv")
head(data) %>% kable(format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE, position = "center", font_size = 12) %>%
  row_spec(0, background = "#287289", color = "white")
```

VAMOS A VER EL NOMBRE DE LAS VARIABLES Y UNA PEQUEÑA DESCRIPCIÓN JUNTO CON EL TIPO DE DATO QUE ES.
```{r}
colnames(data)
```

VARIABLES y tipo:

-**MDVP.Fo.Hz:** Average vocal fundamental frequency / numerica continua

-**MDVP.Fhi.Hz.:** Maximum vocal fundamental frequency / numerica continua

-**MDVP.Flo.Hz:** Minimum vocal fundamental frequency / numerica continua

-**MDVP.Jitter.:** Several measures of variation in fundamental frequency / numerica continua

-**MDVP.Jitter.Abs.:** Several measures of variation in fundamental frequency / numerica continua

-**MDVP.RAP:** Several measures of variation in fundamental frequency / numerica continua

-**MDVP.PPQ:** Several measures of variation in fundamental frequency / numerica continua

-**Jitter.DDP:** Several measures of variation in fundamental frequency / numerica continua

-**MDVP.Shimmer:** Several measures of variation in amplitude / numerica continua

-**MDVP.Shimmer.dB.:** Several measures of variation in amplitude / numerica continua

-**Shimmer.APQ3:** Several measures of variation in amplitude / numerica continua

-**Shimmer.APQ5:** Several measures of variation in amplitude / numerica continua

-**MDVP.APQ:** Several measures of variation in amplitude / numerica continua

-**Shimmer.DDA:** Several measures of variation in amplitude / numerica continua

-**NHR:** measure of ratio of noise to tonal components in the voice / numerica continua

-**HNR:** measure of ratio of noise to tonal components in the voice / numerica continua

-**status:** Health status of the subject (1) - Parkinson's, (0) - healthy / numerica continua

-**RPDE:** nonlinear dynamical complexity measure / numerica continua

-**DFA:** Signal fractal scaling exponent / numerica continua

-**spread1:** nonlinear measure of fundamental frequency variation / numerica continua

-**spread2:** nonlinear measure of fundamental frequency variation / numerica continua

-**D2:** nonlinear dynamical complexity measure / numerica continua

-**PPE:** nonlinear measure of fundamental frequency variation / numerica continua

### PREPROCESAMIENTO INICIAL

PRIMERO VAMOS A CAMBIAR EL NOMBRE DE LA COLUMNA "MDVP.JITTER..." PARA QUE TODAS ESTÉN CON EL MISMO FORMATO. 
```{r}
data <- rename(data, MDVP.Jitter. = MDVP.Jitter...) # tiene 3 puntos cuando otras solo tiene 1. Lo dejamos con un solo punto y asi no tenemos qu cambiar el resto para dejarlas con el mismo formato.
```

ELIMINAMOS LA COLUMNA NAME, PUES NO NOS HARÁ FALTA PARA LOS ANÁLISIS POSTERIORES
```{r}
data["name"] = NULL
```

VEAMOS LA ESTRUCTURA DE NUESTRO DATASET
```{r}
str(data)
```

AQUI PODEMOS OBSERVAR LAS VARIABLES QUE SON NUMERICAS Y LAS QUE DEBERIAN DE SER CATEGORICAS (COMO status)


status ES NUESTRA VARIABLE TARGET Y ES UNA VARIABLE CATEGORICA BINARIA. LA TRANSFORMAMOS A FACTOR
```{r}
data$status = as.factor(data$status)
```


ES MUY IMPORTANTE VER SI NUESTRO DATASET TIENE MISSING VALUES, CUANTOS Y EN QUE COLUMNAS. SI HAY 0, SIN NINGÚN PROBLEMA. SI POR EL CONTRARIO, TENEMOS, DEBEMOS VER QUE HACER CON ELLOS (ELIMINARLOS, IMPUTARLOS, ETC)
```{r}
missing_values = colSums(is.na(data))

missing_values
```


OBSERVAMOS QUE NO HAY NINGÚN MISSING VALUE, LO CUAL NOS QUITA CIERTO PESO EN CUANTO ELIMINACIÓN, IMPUTACIÓN, ETC.

## ANÁLISIS DESCRIPTIVO

UNA FORMA MUY SENCILLA DE VER UN POCO LA MEDIA, DESVIACIÓN ESTANDAR, MINIMOS, MAXIMOS (EN EL CASO DE VARIABLES NUMERICAS) Y EL RECUENTO DE NIVELES (PARA VARIABLES CATEGORICAS) ES A TRAVÉS DEL SUMMARY
```{r}
summary(data)
```
EN ESTE SUMMARY, PODEMOS SACAR CIERTOS DATOS INTERESANTES. POR UN LADO, LAS VARIABLES COMO **MDVP.Fo.Hz.** y **MDVP.Fhi.Hz.** TIENEN VALORES MÍNIMOS BAJOS Y MÁXIMOS ELEVADOS, LO QUE PUEDE REFLEJAR VARIABILIDAD EN LA VOZ DE LOS PACIENTES. VARIABLES COMO **MDVP.Jitter.** y **Shimmer** TIENEN UNA MAYOR DISPERSION, CON VALORES EXTREMOS INDICATIVOS DE VARIABILIDAD EN LA SEÑAL DE LA VOZ, LO QUE PODRÍA SER RELEVANTE PARA IDENTIFICAR PATRONES RELACIONADOS CON LA ENFERMEDAD. ADEMÁS, LA VARIABLE **status** INDICA LA CLASIFICACIÓN DE LOS PACIENTES (0 = Sanos; 1 = Pacientes). 


NO OBSTANTE, HAY FORMAS MÁS BONITAS DE PODER VER ESTOS MISMOS DATOS. A CONTINUACIÓN, PRESENTO UNA ALTERNATIVA MÁS LLAMATIVA

SKIMR
```{r}
library(skimr)

skim(data)
```

SKIM NOS CREA POR UN LADO, UNA SECCIÓN QUE NOS MUESTRA CUÁNTAS VARIABLES SON NUMÉRICAS Y CUÁNTAS CATEGÓRICAS Y, POR OTRO, DOS TIBBLES, QUE SON COMO DATAFRAMES Y SE ORGANIZAN EN CATEGÓRICAS, DANDO LOS CONTEOS, Y EN NUMÉRICAS, DANDO MÁS INFORMACIÓN QUE UN SUMMARY Y MÁS ESTRUCTURADO.




## VISUALIZACIÓN DE DATOS {.tabset}



EN ESTA SECCIÓN, VAMOS A VISUALIZAR LOS DATOS DE DISTINTA FORMA PARA VER LAS DIFERENTES OPCIONES QUE TENEMOS.



### BOXPLOTS

LOS BOXPLOTS SON LOS GRÁFICOS POR EXCELENCIA, PUES NOS PERMITEN VER MUCHOS PARÁMETROS COMO EL RANGO INTERCUARTILICO (NO DE FORMA EXPLICITA), LOS MÍNIMOS Y MAXIMOS, LA MEDIA, MEDIANA Y, MUY IMPORTANTE, LOS OUTLIERS QUE PUDIERA VER. 
```{r}
# Cogemos las variables numericas
variables_numericas = data %>%
  select(where(is.numeric))

# Hacemos un boxplot sencillo
for (var in colnames(variables_numericas)) {
  g = ggplot(data, aes(x = status, y = variables_numericas[[var]], col = status)) +
    geom_boxplot() +
    theme_minimal() +
    labs(x = "status", y = var) +
    ggtitle(paste("Boxplot de", var, "vs status"))
  
  print(g)
    
}
```


OBSERVAMOS DIFERENCIAS SIGNIFICATIVAS EN MDVP.fo.Hz DONDE PARECE HABER UNA MEDIA MÁS BAJA EN LA FRECUENCIA MEDIA EN PERSONAS QUE PADECEN PARKINSON CON RESPECTO A LOS QUE NO. ESTO MISMO OCURRE EN OTRAS MUCHAS VARIABLES. ADEMÁS, PODEMOS VER QUE VARIAS DE NUESTRAS VARIABLES PRESENTAN OUTLIERS. AQUI DEBEMOS REFLEXIONAR Y DECIDIR SI ESTOS OUTLIERS SON POR ERRORES DE MEDICIÓN U OTRO TIPO DE PROBLEMA EXTERNO O SI BIEN SON DATOS REALES AUNQUE SIMPLEMENTE ATÍPICOS. DEPENDIENDO DE LO QUE CONCLUYAMOS, PODEMOS ELIMINARLOS, DEJARLOS O LO QUE MEJOR VEAMOS. TAMBIEN ES INTERESANTE HACER MODELOS CON Y SIN OUTLIERS PARA VER SI EN LA EVALUACIÓN, MEJORAN EL RENDIMIENTO O NO. 


### VIOLIN PLOT

EL VIOLIN PLOT ES MUY ÚTIL SI QUEREMOS VER COMO SE DISTRIBUYE LA DENSIDAD DE NUESTROS DATOS.
```{r}
# Cogemos las variables numericas
variables_numericas = data %>%
  select(where(is.numeric))

# Hacemos un Violin plot sencillo
for (var in colnames(variables_numericas)) {
  g = ggplot(data, aes(x = status, y = variables_numericas[[var]], col = status)) +
    geom_violin() +
    theme_minimal() +
    labs(x = "status", y = var) +
    ggtitle(paste("Boxplot de", var, "vs status"))
  
  print(g)
    
}
```


PODEMOS OBSERVAR, A DIFERENCIA DE LOS BOXPLOTS QUE SON RECTÁNGULOS, UNOS GRÁFICOS QUE NOS PERMITEN VER COMO A DIFERENTES VALORES DE NUESTRAS VARIABLES NUMERICAS, LA DENSIDAD DE PACIENTES QUE HAY.


### DENSITY PLOT
```{r}
# Cogemos las variables numericas
variables_numericas = data %>%
  select(where(is.numeric))

# Hacemos un density plot sencillo
for (var in colnames(variables_numericas)) {
  g = ggplot(data, aes(x = variables_numericas[[var]], fill = status)) +
    geom_density(alpha = 0.5) + # Se puede añádir el facet_wrap para ver las densidades por separado
    theme_minimal() +
    labs(x = var, fill = "Status") +
    ggtitle(paste("Histograma de", var, "por status"))
  
  print(g)
    
}
```


OTRA FORMA DE VISUALIZAR NUESTROS DATOS ES A TRAVÉS DE DENSITY PLOTS, QUE ES UNA REPRESENTACION GRÁFICA DE LA DISTRIBUCION DE UNA VARIABLE CONINUA.


## RELACION VARIABLES Y SELECCIÓN DE LAS MISMAS {.tabset}


ES MUY IMPORTANTE VER COMO SE RELACIONAN NUESTRAS VARIABLES. EN ESTE CASO, SOLO TENEMOS VARIABLES NUMERICAS (Y LA TARGET QUE ES CATEGORICA), POR LO QUE APLICAREMOS LA CORRELACIÓN DE PEARSON.
```{r}
# Hacemos la correlación de pearson
correlacion_numericas = cor(variables_numericas, 
                            method = "pearson", 
                            use = "complete.obs") # ignora valores faltantes

# La visualizamos mediante corrplot
corrplot(correlacion_numericas, method = "color", tl.cex = 0.8)
```


PODEMOS VER QUE VARIA VARIABLES ESTÁN ALTAMENTE CORRELACIONADAS, ES POR ELLO QUE PODEMOS INTENTAR QUITARNOS ALGUNAS DE ELLAS PARA QUE EL MODELO NO CONTENGA RUIDO POR PARTE DE VARIABLES CORRELACIONADAS.

```{r}
# Paso 2: Encontrar índices de variables altamente correlacionadas
highly_correlated_indices <- findCorrelation(correlacion_numericas, cutoff = 0.9)

# Paso 3: Crear un nuevo conjunto de datos sin las variables altamente correlacionadas
variables_no_correlacionadas <- variables_numericas[, -highly_correlated_indices]

# Verifica el nuevo conjunto de datos
head(variables_no_correlacionadas, 5)
```

LO QUE HEMOS HECHO ES COGER LA MATRIZ DE CORRELACIÓN Y HACER UN CUTOFF (UN PUNTO DE CORTE) DONDE LAS VARIABLES SE CORRELACIONAN EN UN 0.9 O MÁS. LUEGO, HEMOS HECHO UN DATASET A PARTIR DEL ORIGINAL DONDE HEMOS COGIDO SOLO AQUELLAS VARIABLES QUE NO ESTÁN CORRELACIONADAS. POR ÚLTIMO, LAS VISUALIZAMOS Y VEMOS QUE AHORA NUESTRO DATASET TIENE 11 VARIABLES, CUANDO ANTES TENÍA 24.



## EVALUACIÓN MODELOS {.tabset}

ANTES DE CONSTRUIR Y EVALUAR NUESTRO MODELO, DEBEMOS ESCALAR NUESTRAS VARIABLES.
```{r}
# Scale dataset

# Paso 1: Calcular parámetros de preprocesamiento
normParams <- preProcess(variables_no_correlacionadas, method=c("range"))

# Paso 2: Imprimir los parámetros de preprocesamiento
print(normParams)

# Paso 3: Transformar el nuevo conjunto de datos
variables_no_correlacionadas <- predict(normParams, variables_no_correlacionadas)

# Paso 4: Agregar la variable objetivo
nuevo_dataset <- cbind(variables_no_correlacionadas, status = data$status)

# Paso 5: Resumen del nuevo conjunto de datos
summary(nuevo_dataset)
```

PODEMOS OBSERVAR LAS VARIABLES NUMERICAS QUE NO ESTÁN ALTAMENTE CORRELACIONADAS, ESCALADAS. EL ESCALAMIENTO ES IMPORTANTE SIEMPRE, AUNQUE SE VUELVE FUNDAMENTAL CUANDO NUESTROS DATOS ESTÁN EN DISTINTAS MEDIDAS (EJEMPLO: KG Y LITROS)




```{r}
str(nuevo_dataset)
```

AQUI VUELVO A VER LA ESTRUCTURA DE MI DATASET FINAL PARA PODER OBSERVARLO BIEN Y VER QUE TODO ESTÁ LISTO. 


### PARTICIÓN DE DATOS, CONSTRUCCIÓN DEL MODELO Y EVALUACIÓN POR VALIDACION CRUZADA



ANTES DE EMPEZAR A CONSTRUIR EL MODELO, ES IMPORTANTE PARTIR LOS DATOS Y HACER UN TRAINCONTROL PARA LA EVALUACIÓN DEL MISMO. SE UTILIZARÁ COMO MÉTODO DE EVALUACIÓN, EL CROSS VALIDATIÓN, CON 10 K-FOLDS Y 3 REPETICIONES, PARA MAYOR EXACTITUD. ADEMÁS, UTILIZAREMOS UNA MÉTRICA SENCILLA PERO POTENTE PARA VER QUE MODELO SE COMPORTA MEJOR, LA PRECISIÓN (ACCURACY)
```{r}
# Cargar librerías
library(caret)
library(randomForest)
library(e1071)

# Establecer semilla para reproducibilidad
set.seed(123)

# Preparar datos
train_index <- createDataPartition(nuevo_dataset$status, p = 0.8, list = FALSE)
train_data <- nuevo_dataset[train_index, ]
test_data <- nuevo_dataset[-train_index, ]

# Configurar el método de validación cruzada
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

# Ajustar el modelo de regresión logística con validación cruzada
modelo_logistico <- train(status ~ ., data = train_data, method = "glm", 
                          family = "binomial", trControl = train_control)

# Ajustar el modelo SVM con validación cruzada
modelo_svm <- train(status ~ ., data = train_data, method = "svmRadial", 
                    trControl = train_control)

# Ajustar el modelo Random Forest con validación cruzada
modelo_rf <- train(status ~ ., data = train_data, method = "rf", 
                   trControl = train_control)

# Imprimir resultados de los modelos
print(modelo_logistico)
print(modelo_svm)
print(modelo_rf)
```



VAMOS A PONER TODOS ESTOS RESULTADOS (EXCEPTO LA MATRIZ DE CONFUSIÓN), EN UNA TABLA PRESENTABLE
```{r}
# Extraer resultados de los modelos
results_logistico <- modelo_logistico$resample
results_svm <- modelo_svm$resample
results_rf <- modelo_rf$resample

# Combinar los resultados
combined_results <- rbind(
  data.frame(Modelo = "Logístico", results_logistico),
  data.frame(Modelo = "SVM", results_svm),
  data.frame(Modelo = "Random Forest", results_rf)
)

# Resumen de la precisión promedio por modelo
summary_table <- aggregate(Accuracy ~ Modelo, data = combined_results, FUN = mean)

# Crear una tabla estilizada
summary_table %>%
  kable("html", escape = FALSE, align = "c", caption = "Precisión Promedio por Modelo") %>%
  kable_styling("striped", full_width = F) %>%
  column_spec(1, bold = TRUE, color = "darkblue") %>%  # Cambiar columna 1 (Modelo)
  column_spec(2, background = "#f2f2f2") %>%           # Cambiar columna 2 (Precisión)
  row_spec(0, bold = TRUE, font_size = 14, color = "white", background = "darkblue")

```

### EXPLICACIONES Y CONCLUSIONES

**MODELO LOGISTICO**

**Muestra:** El modelo se entrenó con 157 muestras y 11 variables predictivas.

**Clases:** Hay 2 clases en la variable objetivo: '0' y '1'.

**Aviso:** El aviso sobre probabilidades ajustadas que son 0 o 1 indica que el modelo se está ajustando demasiado a los datos (overfitting). Esto puede suceder cuando hay una separación clara entre las clases en algunos casos, lo que lleva a que el modelo prediga probabilidades extremas.

**Accuracy:** La precisión del modelo es aproximadamente 82.17%, lo que indica que el modelo es bastante efectivo al clasificar los casos.

**Kappa:** El valor de Kappa es 0.49983, lo que sugiere que la precisión del modelo es mejor que la aleatoria, pero hay espacio para mejoras, ya que valores de Kappa cercanos a 1 indican una buena concordancia.


**SUPPORT VECTOR MACHINE**

**Muestra y Clases:** Al igual que el modelo de regresión logística, utiliza 157 muestras y 11 variables predictivas.


**Resampling:** Los tamaños de muestra son consistentes en todas las iteraciones de validación cruzada.


**Parámetros de Tuning:** La precisión y Kappa se reportan para diferentes valores del parámetro C, que controla la penalización del error. A medida que C aumenta, la precisión también mejora (del 82.02% al 86.04%).


**Kappa:** Con un C de 1.00, Kappa es 0.5439540, lo que indica una mejora en la concordancia respecto al modelo de regresión logística.



**MODELO RANDOM FOREST**

**Muestra y Clases:** Similar a los modelos anteriores, el modelo Random Forest se entrenó con 157 muestras y 11 variables.


**Resampling:** Los tamaños de muestra varían ligeramente, pero son consistentes.


**Parámetros de Tuning:** Se reporta la precisión y Kappa para diferentes valores del parámetro mtry (número de variables aleatorias a considerar en cada división). Con mtry = 2, el modelo alcanza una precisión del 91.52% y un Kappa de 0.7423043, indicando un rendimiento notablemente mejor que los modelos anteriores.


**Conclusiones:** A medida que mtry aumenta, la precisión disminuye, lo que puede indicar que el modelo está funcionando mejor con menos variables consideradas en cada división.


**RESUMEN GENERAL**

**Mejor Modelo:** El Random Forest es el mejor modelo en términos de precisión (91.52%) y Kappa (0.7423), lo que indica una buena capacidad de clasificación.



**Desempeño del SVM:** Aunque el SVM muestra buenas métricas de precisión, el rendimiento no supera al del Random Forest.



**Desempeño de la Regresión Logística:** La regresión logística tiene la menor precisión (82.17%) y Kappa (0.49983), lo que sugiere que, si bien es un buen modelo inicial, no es el más efectivo en este caso.



**Overfitting en Regresión Logística:** El aviso de sobreajuste en la regresión logística indica que se debe tener cuidado al interpretar las predicciones, ya que puede estar sesgado hacia ciertas clases.
