---
title: "Cardiovascular risk prediction"
author: "JOSÉ LUIS"
date: "2024-10-16"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlights: espresso
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# CÓDIGO {.tabset}

A través de este código se podrá ver como un preprocesamiento de los datos da lugar a un buen estudio exploratorio (EDA). Más adelante visualizaremos e indagaremos en la relación existente entre las variables para poder quedarnos con aquellas que pensamos que predicen mejor nuestra variable target (heart_disease) y asi, construir un modelo y evaluarlo para poder poner en manifiesto su precisión.

## LIBRERIAS {.tabset}

```{r}
library(caret)
library(ConfusionTableR)
library(DataExplorer)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(kableExtra)
library(ModelMetrics)
library(openxlsx)
library(plotly)
library(probably)
library(pROC)
library(psych)
library(purrr)
library(randomForest)
library(reshape2)
library(skimr)
library(stringr)
library(tidymodels)
library(tidyverse)
library(univariateML)
library(vip)
library(xgboost)
library(WRS2)
library(GGally)
library(lmtest)
library(e1071)
library(fastDummies)
library(class)
library(ROCR)
library(corrplot)
library(vcd)
library(skimr)
```


## PRIMERA VISUALIZACIÓN {.tabset}


### DATASET Y VARIABLES 
```{r}
data = read.csv("CVD_cleaned.csv")
head(data) %>% kable(format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE, position = "center", font_size = 12) %>%
  row_spec(0, background = "#287289", color = "white")
```

ECHAMOS UN VISTAZO A LAS COLUMNAS Y QUE TIPO DE DATOS REPRESENTAN
```{r}
colnames(data)
```

**VARIABLES:**


**General_Health:** Categoriga ordinal

**Checkup:** categorica nominal

**Exercise:** Binaria

**Heart_Disease:** Binaria

**Skin_Cancer:** Binaria

**Other_Cancer:** Binaria

**Depression:** Binaria

**Diabetes:** Categorica nominal

**Arthritis:** Binaria

**Sex:** Binaria

**Age_Category:** categorica ordinal

**Height_.cm.:** Numerica continua

**Weight_.kg.:** Numerica continua

**BMI:** Numerica continua

**Smoking_History:** Binaria

**Alcohol_Consumption:** numerica discreta

**Fruit_Consumption:** numerica discreta

**Green_Vegetables_Consumption:** numerica discreta

**FriedPotato_Consumption:** numerica discreta


### PREPROCESAMIENTO INICIAL

CONVERTIMOS LAS VARIABLES NECESARIAS A CATEGORICAS PARA 1) HACER GRÁFICOS NECESARIOS Y 2) UN BUEN PREPROCESAMIENTO AVANZADO PARA EL ESCALADO DE VARIABLES
```{r}
data$General_Health = as.factor(data$General_Health)
data$Checkup = as.factor(data$Checkup)
data$Exercise = as.factor(data$Exercise)
data$Skin_Cancer = as.factor(data$Skin_Cancer)
data$Other_Cancer = as.factor(data$Other_Cancer)
data$Depression = as.factor(data$Depression)
data$Diabetes = as.factor(data$Diabetes)
data$Arthritis = as.factor(data$Arthritis)
data$Sex = as.factor(data$Sex)
data$Age_Category = as.factor(data$Age_Category)
data$Smoking_History = as.factor(data$Smoking_History)
data$Heart_Disease = as.factor(data$Heart_Disease)
```


VAMOS A VER CUAL ES LA ESTRUCTURA DE NUESTRO DATASET
```{r}
str(data)
```


COMPROBAMOS SI HAY MISSING VALUES O DUPLICADOS Y LOS ELIMINAMOS EN CASO AFIRMATIVO.
```{r}
missing_values = colSums(is.na(data))
missing_values
```



ES INTERESANTE NO SOLO COMPROBAR SI HAY MISSING VALUES, SINO TAMBIÉN COMPROBAR SI HAY DUPLICADOS PARA QUE NO HAYA RUIDO EN NUESTRO DATASET. HAY QUE TENER EN CUENTA TAMBIÉN EL NÚMERO DE DUPLICADOS QUE HAYA, PERO NUESTRO DATASET ES LO SUFICIENTEMENTE GRANDE COMO PARA QUE EL NUMERO DE DUPLICADOS NO NOS ALARME.
```{r}
# Verificar si hay duplicados
duplicados <- duplicated(data)
# Mostrar filas duplicadas
# data[duplicados, ] Escondo este paso para que no moleste en el html final
```
HEMOS GENERADO UNA TABLA QUE NOS INDICA LA POSICION (DE LA FILA) DEL DUPLICADO.


BORRAMOS LOS DUPLICADOS YA QUE 1) SON POCOS Y 2) PODRIAN GENERAR RUIDO INNECESARIO.
```{r}
data <- distinct(data)
```


## ANÁLISIS DESCRIPTIVO


USAREMOS PRIMERO UN SUMMARY, QUE ES UNA FORMA MÁS VULGAR DE VER NUESTROS DATOS Y LUEGO VAMOS A UTILIZAR LA FUNCION SKIM DEL PAQUETE SKIMR PARA VISUALIZARLOS DE UNA FORMA MÁS BONITA, CLARA Y PROFESIONAL, DENTRO DE QUE LO MÁS PROFESIONAL SIEMPRE SERÁ HACER LOS CALCULOS POR NOSOTROS MISMOS Y PRESENTARLOS EN UN DATAFRAME CON UN KABLE EXTRA. AQUI, YO LO HAGO ASI PARA AHORRAR TIEMPO Y, PORQUE EN ESENCIA, VA A MOSTRAR LO MISMO CON MENOS LINEAS DE CÓDIGO. SI QUISIERAMOS HACER UNA PRESENTACIÓN, UTILIZARIAMOS SIEMPRE OTROS MÉTODOS MÁS SOFISTICADOS.
```{r}
summary(data)
```


SKIM
```{r}
skim(data)
```
ES INTERESANTE ALGUNOS DE LOS RESULTADOS QUE NOS HAN SALIDO. POR EJEMPLO, DE MEDIA EN ALTURA ES 1.70m Y PESO DE 83.89 Kg. LA MEDIA DEL BMI ES DE 28, QUE ES UN POCO DE SOBREPESO AUNQUE TAMPOCO ALGO GRAVE. ES DECIR, ESTAMOS VIENDO A UNA POBLACIÓN QUE, POR SU ESTATURA, ESTÁ EN UN BMI UN POCO ALTO, LO CUAL PODRÍA SER CLAVE EN ENFERMEDADES CARDIOVASCULARES. NO OBSTANTE, TAMBIEN TENEMOS QUE TENER EN CUENTA QUE LA DESVIACIÓN ESTANDAR PARA EL PESO ES DE 21.34, ES DECIR, QUE ES GRANDE. ES POR ESTO QUE MUCHAS VECES NO NOS DEBEMOS FIJAR TANTO EN LA MEDIA SINO EN LA MEDIANA (1.70, 81.65, 27.44) DONDE SE OBSERVAN BAJADAS PARA EL PESO Y BMI. 


## VISUALIZACIÓN DE LOS DATOS {.tabset}

### VARIABLES NUMERICAS - TARGET - BOXPLOT

```{r}
variables_numericas = data %>%
  select(where(is.numeric))

# Hacemos un boxplot sencillo
for (var in colnames(variables_numericas)) {
  g = ggplot(data, aes(x = Heart_Disease, y = variables_numericas[[var]], col = Heart_Disease)) +
    geom_boxplot() +
    theme_minimal() +
    labs(x = "Heart_Disease", y = var) +
    ggtitle(paste("Boxplot de", var, "vs Heart_Disease"))
  
  print(g)
    
}
```
NO VEMOS APENAS DIEFERENCIAS SIGNIFICATIVAS EN LAS VARIABLES NUMERICAS. AUNQUE, LO QUE SI ES INTERESANTE, ES EL NÚMERO TAN ELEVADO DE OUTLIERS QUE HAY. EN UN DATASET CON TANTAS OBSERVACIONES Y CON VARIABLES COMO PUEDEN SER PESO, ALTURA, BMI, ETC SEGURO QUE HABRÁ ERRORES EN LA MEDICIÓN. PERO TENEMOS QUE PENSAR, ¿SON TAN GRANDES LOS ERRORES COMO PARA QUE CONSTITUYAN VALORES ATIPICOS O SON SIMPLES DATOS REALES QUE SE SALEN DE LO COMÚN? BIEN, LO QUE SE HARÁ EN ESTE ESTUDIO ES HACER MODELOS CON Y SIN OUTLIERS Y VER LAS DIFERENCIAS PARA ASI QUITARNOS LAS POSIBLES DUDAS. 

A CONTINUACIÓN, SE PRESENTARÁN OTRA FORMA DE VISUALIZAR LOS DATOS

### VARIABLES NUMERICAS - TARGET - VIOLIN PLOT
```{r}
variables_numericas = data %>%
  select(where(is.numeric))

# Hacemos un violin plot sencillo
for (var in colnames(variables_numericas)) {
  g = ggplot(data, aes(x = Heart_Disease, y = variables_numericas[[var]], col = Heart_Disease)) +
    geom_violin() +
    theme_minimal() +
    labs(x = "Heart_Disease", y = var) +
    ggtitle(paste("Boxplot de", var, "vs Heart_Disease"))
  
  print(g)
    
}
```

AHORA VAMOS A VISUALIZAR LAS VARIABLES CATEGORICAS 

### VARIABLES CATEGORICAS - TARGET - GRAFICO DE BARRAS
```{r}
variables_categoricas = data %>%
  select(where(is.factor))

for (var in colnames(variables_categoricas)) {
  # Hacemos un condicional para que cuando toque hearth_disease, no haga el gráfico
  if (var == "Heart_Disease") next
  
  g = ggplot(data, aes(x = variables_categoricas[[var]], fill = Heart_Disease)) +
    theme_minimal() +
    geom_bar(position = "dodge") +
    labs(x = var, y = "Conteo", fill = "Heart_Disease") + 
    ggtitle(paste("Diagrama de dispersión de", var, "vs Variable Heart_Disease"))
  
  print(g)
  
}

```
EN ESTOS GRÁFICOS SI QUE HAY RESULTADOS MÁS INTERESANTES. POR EJEMPLO, VEMOS QUE LA SALUD GENERAL SI INCIDE EN ENFERMEDADES CARDIOVASCULARES, SIENDO QUE EXCELLENT ES EL QUE MENOS CASOS TIENE. LA EDAD PARECE TAMBIEN SER SIGNIFICATIVA, PUES A MEDIDA QUE AUMENTADOS LA EDAD, LOS CASOS TAMBIÉN AUMENTAN. PARECE QUE EL SEXO PODRIA SER IMPORTANTE, PUES HAY MÁS HOMBRES QUE MUJERES, AUNQUE EL AUMENTO NO PARECE SER MUY SIGNIFICATIVO.



A CONTINUACIÓN, SE VERÁN OTRAS FORMAS DE VISUALIZAR COMO LAS VARIABLES CATEGORICAS SE COMPORTAN CONTRA LA VARIABLE TARGET

### VARIABLES CATEGORICAS - TARGET - GRAFICO DE BARRAS - APILADAS
```{r}
variables_categoricas = data %>%
  select(where(is.factor))

for (var in colnames(variables_categoricas)) {
  g = ggplot(data, aes(x = variables_categoricas[[var]], fill = Heart_Disease)) +
    theme_minimal() +
    geom_bar(position = "stack") +
    labs(x = var, y = "Conteo", fill = "Heart_Disease") + 
    ggtitle(paste("Diagrama de dispersión de", var, "vs Variable Heart_Disease"))
  
  print(g)
  
}

```
EL GRAFICO DE BARRAS APILADAS ME GUSTA MUCHO PORQUE NO OCUPA TANTO ESPACIO (CUANDO HAY MUCHOS NIVELES EN UNA VARIABLE CATEGORICA) Y TE DICE LA MISMA INFORMACIÓN QUE EL DE BARRAS NORMAL.


### VARIABLES CATEGORICAS - TARGET - MOSAICO PLOT
```{r}
# Seleccionar las variables categóricas del dataset
variables_categoricas = data %>%
  select(where(is.factor))

# Crear un bucle para iterar sobre cada variable categórica
for (var in colnames(variables_categoricas)) {
  
  # Crear la fórmula dinámica para el mosaic plot
  formula_mosaico = as.formula(paste("~", var, "+ Heart_Disease"))
  
  # Generar el mosaic plot
  mosaic(formula_mosaico, data = data, shade = TRUE, 
         main = paste("Mosaic plot de", var, "vs Heart_Disease"))
}
```
LOS MOSAICO PLOTS SON MUY UTILES PARA VISUALIZAR LA RELACION ENTRE DOS O INCLUSO MÁS VARIABLES. ESTE GRAFICO SE DESCOMPONE EN UN RECTANGULO DE BLOQUES QUE REPRESENTAN LAS FRECUENCIAS DE CADA COMBINACIÓN DE LAS VARIABLES CATEGORICAS. ADEMÁS, TE DA LOS RESIDUOS Y EL P-VALOR DE ESTOS.


### VARIABLES CATEGORICAS - TARGET - Proportional bar chart
```{r}
variables_categoricas = data %>%
  select(where(is.factor))

for (var in colnames(variables_categoricas)) {
  g = ggplot(data, aes(x = variables_categoricas[[var]], fill = Heart_Disease)) +
    theme_minimal() +
    geom_bar(position = "fill") +
    labs(x = var, y = "Conteo", fill = "Heart_Disease") + 
    ggtitle(paste("Diagrama de dispersión de", var, "vs Variable Heart_Disease"))
  
  print(g)
  
}
```
ES UN GRAFICO DE BARRAS APILADAS PERO POR PROPORCIONES, DONDE SE VA A VER REFLEJADO DE MEJOR MANERA LOS RESULTADOS EN VARIABLES COMO LA EDAD.


### VARIABLES CATEGORICAS - TARGET - HEATMAP
```{r}
# Crear un bucle para iterar sobre cada variable categórica
for (var in colnames(variables_categoricas)) {
  
  # Crear tabla de frecuencias
  tabla_frecuencias <- as.data.frame(table(data[[var]], data$Heart_Disease))
  colnames(tabla_frecuencias) <- c("Categoría", "Heart_Disease", "Frecuencia")
  
  # Graficar el heatmap
  g <- ggplot(tabla_frecuencias, aes(x = Categoría, y = Heart_Disease, fill = Frecuencia)) +
    geom_tile(color = "white") +  # Añadir bordes blancos a las celdas
    scale_fill_gradient(low = "lightblue", high = "darkblue") +  # Escala de colores
    labs(x = var, y = "Heart Disease", fill = "Frecuencia") +
    ggtitle(paste("Heatmap de", var, "vs Heart_Disease")) +
    theme_minimal()
  
  # Mostrar el heatmap
  print(g)
}
```
LOS HEATMAPS SON UNO DE LOS MÉTODOS DE VISUALIZACIÓN PARA VARIABLES CATEGORICAS MÁS CLAROS QUE EXISTEN. ADEMÁS, SON MUY FACILES DE INTERPRETAR, PUES SE NOS CREAN TANTAS CUADRAS COMO COMBINACIONES HAYA Y SE PONE UN COLOR SEGÚN LA FRECUENCIA.


## TRATAMIENTO OUTLIER


EN ESTE CASO, VAMOS A ELIMINARLOS YA QUE ESTÁN HACIENDO DEMASIADO RUIDO Y ESO PUEDE DISTORSIONAR MUCHO LOS RESULTADOS. NO OBSTANTE, VEREMOS SI NUESTROS MODELOS SON MEJORES O PEORES CUANDO NO TRATEMOS LOS OUTLIERS.
```{r}
# Cargar las librerías necesarias
library(dplyr)

# Definir las columnas numéricas para eliminar outliers
numeric_columns <- select_if(data, is.numeric) %>% colnames()

# Calcular el IQR para las columnas numéricas
Q1 <- apply(data[numeric_columns], 2, quantile, 0.25)
Q3 <- apply(data[numeric_columns], 2, quantile, 0.75)
IQR <- Q3 - Q1

# Establecer un valor umbral para la detección de outliers (por ejemplo, 1.5 veces el IQR)
threshold <- 1.5

# Crear una máscara para los outliers en las columnas numéricas
outlier_mask <- apply(data[numeric_columns], 1, function(row) {
  any(row < (Q1 - threshold * IQR) | row > (Q3 + threshold * IQR))
})

# Eliminar las filas con outliers del dataset
data_cleaned <- data[!outlier_mask, ]

# Imprimir el número de filas eliminadas
num_rows_removed <- nrow(data) - nrow(data_cleaned)
cat("Número de filas eliminadas debido a outliers:", num_rows_removed, "\n")

```


```{r}
dim(data_cleaned)
```

## RELACION VARIABLES {.tabset}


AQUI VAMOS A VER COMO LAS VARIABLES NUMERICAS Y CATEGORICAS SE CORRELACIONAN ENTRE SI Y SI PODEMOS ELIMINAR ALGUNA 


### VARIABLES NUMERICAS
```{r}

variables_numericas_cleaned = data_cleaned %>%
  select(where(is.numeric))

# Hacemos la correlación de pearson
correlacion_numericas = cor(variables_numericas_cleaned, 
                            method = "pearson", 
                            use = "complete.obs") # ignora valores faltantes

# La visualizamos mediante corrplot
corrplot(correlacion_numericas, method = "color", tl.cex = 0.8)
```


ESTE CODIGO NOS PERMITE VER QUE VARIABLES ESTÁN ALTAMENTE CORRELACIONADAS EN, FUNCIÓN, DE UN PUNTO DE CORTE (cutoff) QUE SEÑALEMOS.
LO NORMAL ES ENTRE 0.7-0.9
```{r}
# Paso 2: Encontrar índices de variables altamente correlacionadas
highly_correlated_indices <- findCorrelation(correlacion_numericas, cutoff = 0.8)

# Paso 3: Crear un nuevo conjunto de datos sin las variables altamente correlacionadas
variables_no_correlacionadas <- variables_numericas_cleaned[, -highly_correlated_indices]

# Verifica el nuevo conjunto de datos
head(variables_no_correlacionadas, 5)
```
Weight.kg y BMI ESTABAN MUY CORRELACIONADAS, ASI QUE SE ELIMINÓ Weight.kg


### VARIABLES CATEGORICAS
```{r}
# Extraemos solo las variables categóricas
variables_categoricas = data_cleaned %>%
  select(where(is.factor))

# Función para calcular el V de Cramer entre dos variables
calcular_cramer_v <- function(var1, var2) {
  tabla = table(var1, var2)
  resultado = assocstats(tabla)
  return(resultado$cramer)
}

# Crear una matriz vacía para almacenar los valores de V de Cramer
num_vars = ncol(variables_categoricas)
matriz_cramer = matrix(NA, nrow = num_vars, ncol = num_vars)
colnames(matriz_cramer) = colnames(variables_categoricas)
rownames(matriz_cramer) = colnames(variables_categoricas)

# Llenar la matriz con los valores de V de Cramer
for (i in 1:num_vars) {
  for (j in i:num_vars) {
    if (i == j) {
      matriz_cramer[i, j] = 1  # La correlación de una variable consigo misma es 1
    } else {
      cramer_v = calcular_cramer_v(variables_categoricas[[i]], variables_categoricas[[j]])
      matriz_cramer[i, j] = cramer_v
      matriz_cramer[j, i] = cramer_v  # La matriz es simétrica
    }
  }
}

# Mostrar la matriz
print(matriz_cramer)
```

```{r}
#umbral = 0.6

# Identificar pares de variables altamente correlacionadas
#altamente_correlacionadas = which(matriz_cramer > umbral & matriz_cramer < 1, arr.ind = TRUE)

# Mostrar los pares de variables altamente correlacionadas
#for (i in 1:nrow(altamente_correlacionadas)) {
  #var1 = rownames(matriz_cramer)[altamente_correlacionadas[i, 1]]
  #var2 = colnames(matriz_cramer)[altamente_correlacionadas[i, 2]]
  #cat("Las variables", var1, "y", var2, "están altamente correlacionadas con un V de Cramer de", matriz_cramer[altamente_correlacionadas[i, 1], altamente_correlacionadas[i, #2]], "\n")
#}
```
ESTE CODIGO ESTA OCULTO, PERO ES PORQUE GENERA UN ERROR AL NO HABER VARIABLES CATEGORICAS ALTAMENTE CORRELACIONADAS. LO DEJO ASI PORQUE SI NO, NO ME DEJARIA EXPORTAR ESTE ARCHIVO A HTML.



COGEMOS TODAS LAS VARIABLES MENOS WEIGHT.KG

## ENTRENAMIENTO MODELOS {.tabset}

ANTES DE CONSTRUIR Y EVALUAR MODELOS, DEBEMOS ESCALAR LAS VARIABLES NUMERICAS Y CATEGORICAS


### ESCALADO DE VARIABLES


NUMERICAS
```{r}
# Scale dataset

# Paso 1: Calcular parámetros de preprocesamiento
normParams <- preProcess(variables_no_correlacionadas, method=c("range"))

# Paso 2: Imprimir los parámetros de preprocesamiento
print(normParams)
```

```{r}
# Paso 3: Transformar el nuevo conjunto de datos
variables_numericas_e <- predict(normParams, variables_no_correlacionadas)

# Vamos a ver como quedaron las variables numericas escaladas
summary(variables_numericas_e)
```

CATEGORICAS BINARIAS
```{r}
data_cleaned$Heart_Disease = ifelse(data_cleaned$Heart_Disease == "Yes", 1,0)
data_cleaned$Exercise = ifelse(data_cleaned$Exercise == "Yes", 1,0)
data_cleaned$Skin_Cancer = ifelse(data_cleaned$Skin_Cancer == "Yes", 1,0)
data_cleaned$Other_Cancer = ifelse(data_cleaned$Other_Cancer == "Yes", 1,0)
data_cleaned$Depression = ifelse(data_cleaned$Depression == "Yes", 1,0)
data_cleaned$Arthritis = ifelse(data_cleaned$Arthritis == "Yes", 1,0)
data_cleaned$Sex = ifelse(data_cleaned$Sex == "Female", 1,0)
data_cleaned$Smoking_History = ifelse(data_cleaned$Smoking_History == "Yes", 1,0)
```


CONVETIMOS NUESTRA VARIABLE TARGET A FACTOR PARA UN MEJOR RENDIMIENTO DE LOS MODELOS
```{r}
data_cleaned$Heart_Disease = as.factor(data_cleaned$Heart_Disease)
```


CATEGORICAS ORDINALES


PRIMERO VAMOS A VER LOS NIVELES DE CADA VARIABLE PARA LUEGO ESCALARLA CORRECTAMENTE
```{r}
niveles_General_Health = levels(data_cleaned$General_Health)
niveles_General_Health

niveles_Checkup = levels(data_cleaned$Checkup)
niveles_Checkup

niveles_Age_Category = levels(data_cleaned$Age_Category)
niveles_Age_Category

niveles_Diabetes = levels(data_cleaned$Diabetes)
niveles_Diabetes # Incluyo aqui diabetes solo para saber los niveles, no voy a escalarla como una variable categorica ordinal
```



AHORA LAS ESCALAMOS
```{r}
# Escalando la variable ordinal General_Health
data_cleaned <- data_cleaned %>%
  mutate(General_Health = factor(General_Health, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), 
                        labels = c(1, 2, 3, 4, 5), ordered = TRUE))

# Escalando la variable ordinal Checkup
data_cleaned <- data_cleaned %>%
  mutate(Checkup = factor(Checkup, levels = c("Never", "5 or more years ago", "Within the past 5 years", "Within the past 2 years", "Within the past year"), 
                        labels = c(1, 2, 3, 4, 5), ordered = TRUE))

# Escalando la variable ordinal Checkup
data_cleaned <- data_cleaned %>%
  mutate(Age_Category = factor(Age_Category, levels = c("18-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59", "60-64", "65-69", "70-74", "75-79", "80+"), 
                        labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), ordered = TRUE))
```


VARIABLES CATEGORICAS NOMINALES
```{r}
# Asegúrate de que Diabetes es un factor
data_cleaned$Diabetes <- as.factor(data_cleaned$Diabetes)

# Aplicar la codificación one-hot
diabetes_dummies <- model.matrix(~ Diabetes - 1, data = data_cleaned)

# Convertir a data frame
diabetes_dummies <- as.data.frame(diabetes_dummies)

# Combinar el nuevo DataFrame con las variables restantes
data_cleaned <- data_cleaned %>%
  select(-Diabetes)  # Eliminar la columna original de Diabetes
```



POR ÚLTIMO, UNIMOS LAS NUEVAS VARIABLES NUMERICAS ESCALADAS CON LAS CATEGORICAS ESCALADAS 
```{r}
# Primero quitamos las variables numericas originales del dataset
numerical_cols <- sapply(data_cleaned, is.numeric)
data_cleaned_non_numeric <- data_cleaned[, !numerical_cols]

# Uno las variables numericas escaladas con el resto del dataset
nuevo_dataset = cbind(variables_numericas_e, data_cleaned_non_numeric, diabetes_dummies)


str(nuevo_dataset)
```

HACEMOS UN SUMMARY RAPIDO PARA VER COMO QUEDAN
```{r}
summary(nuevo_dataset)
```



### PARTICION DE LOS DATOS
```{r}
set.seed(123)

# Preparar datos
train_index <- createDataPartition(nuevo_dataset$Heart_Disease, p = 0.8, list = FALSE)
train_data <- nuevo_dataset[train_index, ]
test_data <- nuevo_dataset[-train_index, ]
```



### ENTRENAMIENTO MODELOS - VALIDACIÓN CRUZADA
```{r}
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

# Ajustar el modelo de regresión logística con validación cruzada
modelo_logistico <- train(Heart_Disease ~ ., data = train_data, method = "glm", 
                          family = "binomial", trControl = train_control)

# Imprimir resultados de los modelos
print(modelo_logistico)
```
BIEN, UNA VEZ OBTENIDOS LOS RESULTADOS, VAMOS A HACERLO SIN EL TRATAMIENTO DE OUTLIERS Y VEAMOS QUE MODELO PARECE TENER UN ACCURACY MÁS ALTO Y UN KAPPA MÁS PEQUEÑO. CABE DESTACAR QUE PARA ESTE PROYECTO SOLO UTILIZAREMOS EL MODELO LOGISTICO, PUES AL TRATARSE DE UN VOLUMEN TAN GRANDE DE DATOS, MODELOS COMO RANDOM FOREST O SUPPORT VECTOR MACHINE ME TARDAN DEMASIADO. NO OBSTANTE, DEJO QUE CUALQUIERA DE LOS QUE VEAN ESTE PROYECTO, SE ANIMEN Y COMPARTAN SUS RESULTADOS CON OTROS MODELOS PREDICTIVOS.


### CONSTRUCCION Y EVALUACION DE MODELO CON OUTLIERS



EMPEZAREMOS DESDE LA RELACION DE LAS VARIABLES, QUE ES CUANDO CAMBIAMOS DE DATA A DATA_CLEANED Y SEGUIREMOS LOS MISMOS PASOS
```{r}
variables_numericas = data %>%
  select(where(is.numeric))

# Hacemos la correlación de pearson
correlacion_numericas_2 = cor(variables_numericas, 
                            method = "pearson", 
                            use = "complete.obs") # ignora valores faltantes

# La visualizamos mediante corrplot
corrplot(correlacion_numericas_2, method = "color", tl.cex = 0.8)
```
```{r}
# Paso 2: Encontrar índices de variables altamente correlacionadas
highly_correlated_indices_2 <- findCorrelation(correlacion_numericas_2, cutoff = 0.8)

# Paso 3: Crear un nuevo conjunto de datos sin las variables altamente correlacionadas
variables_no_correlacionadas_2 <- variables_numericas[, -highly_correlated_indices_2]

# Verifica el nuevo conjunto de datos
head(variables_no_correlacionadas_2, 5)
```
NOS SALTAMOS EL PASO DE LAS VARIABLES CATEGORICAS PORQUE YA VIMOS QUE NINGUNA ESTA ALTAMENTE CORRELACIONADA.



ESCALADO VARIABLES NUMERICAS
```{r}
# Scale dataset

# Paso 1: Calcular parámetros de preprocesamiento
normParams_2 <- preProcess(variables_no_correlacionadas_2, method=c("range"))

# Paso 2: Imprimir los parámetros de preprocesamiento
print(normParams_2)
```

```{r}
# Paso 3: Transformar el nuevo conjunto de datos
variables_numericas_e_2 <- predict(normParams_2, variables_no_correlacionadas_2)

# Vamos a ver como quedaron las variables numericas escaladas
summary(variables_numericas_e_2)
```



ESCALADO VARIABLES CATEGORICAS BINARIAS
```{r}
data$Heart_Disease = ifelse(data$Heart_Disease == "Yes", 1,0)
data$Exercise = ifelse(data$Exercise == "Yes", 1,0)
data$Skin_Cancer = ifelse(data$Skin_Cancer == "Yes", 1,0)
data$Other_Cancer = ifelse(data$Other_Cancer == "Yes", 1,0)
data$Depression = ifelse(data$Depression == "Yes", 1,0)
data$Arthritis = ifelse(data$Arthritis == "Yes", 1,0)
data$Sex = ifelse(data$Sex == "Female", 1,0)
data$Smoking_History = ifelse(data$Smoking_History == "Yes", 1,0)
```




CONVERTIMOS NUESTRA VARIABLE TARGET A FACTOR PARA UN MEJOR RENDIMIENTO DE LOS MODELOS
```{r}
data$Heart_Disease = as.factor(data$Heart_Disease)
```




ESCALADO VARIABLES CATEGORICAS ORDINALES
```{r}
# Escalando la variable ordinal General_Health
data <- data %>%
  mutate(General_Health = factor(General_Health, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), 
                        labels = c(1, 2, 3, 4, 5), ordered = TRUE))

# Escalando la variable ordinal Checkup
data <- data %>%
  mutate(Checkup = factor(Checkup, levels = c("Never", "5 or more years ago", "Within the past 5 years", "Within the past 2 years", "Within the past year"), 
                        labels = c(1, 2, 3, 4, 5), ordered = TRUE))

# Escalando la variable ordinal Checkup
data <- data %>%
  mutate(Age_Category = factor(Age_Category, levels = c("18-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59", "60-64", "65-69", "70-74", "75-79", "80+"), 
                        labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), ordered = TRUE))
```



ESCALADO VARIABLES CATEGORICAS NOMINALES
```{r}
# Asegúrate de que Diabetes es un factor
data$Diabetes <- as.factor(data$Diabetes)

# Aplicar la codificación one-hot
diabetes_dummies <- model.matrix(~ Diabetes - 1, data = data)

# Convertir a data frame
diabetes_dummies <- as.data.frame(diabetes_dummies)

# Combinar el nuevo DataFrame con las variables restantes
data <- data %>%
  select(-Diabetes)  # Eliminar la columna original de Diabetes
```



POR ÚLTIMO, UNIMOS LAS NUEVAS VARIABLES NUMERICAS ESCALADAS CON LAS CATEGORICAS ESCALADAS 
```{r}
# Primero quitamos las variables numericas originales del dataset
numerical_cols <- sapply(data, is.numeric)
data_non_numeric <- data[, !numerical_cols]

# Uno las variables numericas escaladas con el resto del dataset
nuevo_dataset_2 = cbind(variables_numericas_e_2, data_non_numeric, diabetes_dummies)


str(nuevo_dataset_2)
```
```{r}
set.seed(123)

# Preparar datos
train_index <- createDataPartition(nuevo_dataset_2$Heart_Disease, p = 0.8, list = FALSE)
train_data <- nuevo_dataset_2[train_index, ]
test_data <- nuevo_dataset_2[-train_index, ]
```


```{r}
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

# Ajustar el modelo de regresión logística con validación cruzada
modelo_logistico_2 <- train(Heart_Disease ~ ., data = train_data, method = "glm", 
                          family = "binomial", trControl = train_control)

# Imprimir resultados de los modelos
print(modelo_logistico_2)
```



## RESULTADOS Y CONCLUSIONES
```{r}
library(gt)

# Extraer las métricas de desempeño
resultado_logistico <- data.frame(
  Modelo = "Logístico (sin outliers)",
  Accuracy = modelo_logistico$results$Accuracy,
  Kappa = modelo_logistico$results$Kappa
)

resultado_logistico_2 <- data.frame(
  Modelo = "Logístico (con outliers)",
  Accuracy = modelo_logistico_2$results$Accuracy,
  Kappa = modelo_logistico_2$results$Kappa
)

# Unir los resultados en una tabla
resultados_completos <- rbind(resultado_logistico, resultado_logistico_2)

# Crear una tabla estilizada con gt
resultados_completos %>%
  gt() %>%
  tab_header(
    title = "Comparación de Modelos Logísticos"
  ) %>%
  tab_spanner(
    label = "Desempeño",
    columns = vars(Accuracy, Kappa)
  ) %>%
  fmt_number(
    columns = vars(Accuracy, Kappa),
    decimals = 3
  ) %>%
  tab_style(
    style = list(
      cell_borders(sides = "all", color = "gray", weight = 1),
      cell_text(weight = "bold")
    ),
    locations = cells_title()
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightgray")
    ),
    locations = cells_body(columns = everything())
  ) %>%
  tab_style(
    style = list(
      cell_text(align = "center")
    ),
    locations = cells_column_labels()
  )

```



OTRA FORMA DE PRESENTAR LOS RESULTADOS
```{r}
# Extraer las métricas de desempeño
resultado_logistico <- data.frame(
  Modelo = "Logístico (sin outliers)",
  Accuracy = modelo_logistico$results$Accuracy,
  Kappa = modelo_logistico$results$Kappa
)

resultado_logistico_2 <- data.frame(
  Modelo = "Logístico (con outliers)",
  Accuracy = modelo_logistico_2$results$Accuracy,
  Kappa = modelo_logistico_2$results$Kappa
)

# Unir los resultados en una tabla
resultados_completos <- rbind(resultado_logistico, resultado_logistico_2)

# Crear una tabla con kableExtra
resultados_completos %>%
  kable("html", col.names = c("Modelo", "Accuracy", "Kappa"), caption = "Comparación de Modelos Logísticos") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "responsive"),
    font_size = 14,
    position = "center",
    full_width = F
  ) %>%
  column_spec(1, bold = TRUE, color = "white", background = "#4CAF50") %>%  # Verde más suave
  column_spec(2:3, color = "black", background = "#E8F5E9") %>%  # Fondo claro y texto negro
  row_spec(0, bold = TRUE, color = "white", background = "#388E3C") %>%  # Fila de encabezado en verde oscuro
  add_header_above(c(" " = 1, "Desempeño" = 2))
```


RESULTADOS **MODELO LOGISTICO SIN OUTLIERS:**

VEMOS QUE TIENE UNA PRECISION (ACCURACY) DE 0.914, LO CUAL ES BASTANTE ALTO, JUNTO CON UN VALOR KAPPA (TAMBIEN CONOCIDO COMO INDICE DE KAPPA DE COHEN) DE 0.073. KAPPA ES UNA MEDIDA DE LA CONSISTENCIA O ACUERDO ENTRE DOS OBSERVADORES O CLASIFICADORES, COMO ES EL CASO DE NUESTRA VARIABLE TARGET QUE NOS DICE SI PRESENTAN O NO ENFERMEDAD CARDIOVASCULAR. ESTE VALOR BAJO SIGNIFICA QUE EL MODELO PREDICE DE FORMA PRECISA PERO DE FORMA ALEATORIA EN LA MAYORIA DE CASOS (por ejemplo, al predecir la clase mayoritaria con alta frecuencia), LO QUE NO REFLEJA UN VERDADERO ACUERDO SIGNIFICATIVO CON LAS CLASES REALES (SI / NO). 

RESULTADOS **MODELO LOGISTICO CON OUTLIERS:**

VEMOS, QUE DE IGUAL FORMA QUE EL MODELO SIN OUTLIERS, TIENE UNA PRECISION (ACCURACY) DE 0.918, LO CUAL ES BASTANTE ALTO TAMBIÉN, JUNTO CON UN VALOR KAPPA DE 0.066. 

**¿QUE ESTÁ OCURRIENDO?**

PUEDE HABER VARIAS EXPLICACIONES ANTE ESTE SUCESO:

**Clase desbalanceada:** Si el conjunto de datos tiene una distribución desequilibrada entre las clases (por ejemplo, muchas más instancias de una clase que de la otra), el modelo podría predecir correctamente la clase mayoritaria con frecuencia, lo que eleva el accuracy pero no refleja un acuerdo real con la clase minoritaria.

**Modelo sobreajustado o poco informativo:** Aunque el modelo tiene un accuracy alto, podría no estar capturando bien la información para las predicciones de la clase minoritaria o los casos más complejos. El bajo Kappa indica que las predicciones no están completamente alineadas con las clases reales, más allá de lo que ocurriría por azar.

SI NOS VAMOS A LA VARIABLE TARGET Y SU CONTEO, OBSERVAMOS QUE, EFECTIVAMENTE, HAY 283.803 CASOS NEGATIVOS Y TAN SOLO 24.971 POSITIVOS. ESTO HACE QUE LA DISTRIBUCIÓN ESTÉ MUY DESBALANCEADA, EXPLICANDO UN ALTO ACCURACY (PROBABLEMENTE PARA LOS CASOS NEGATIVOS) Y UN VALOR BAJO DE KAPPA. ES DECIR, AL HABER TANTISIMOS CASOS NEGATIVOS, EL SIMPLE AZAR HACE QUE NUESTRO MODELO PREDIGA BIEN, PUES LA MAYORIA DE ESTOS SON NEGATIVOS. SI TUVIERAMOS UN BALANCE ENTRE LAS CLASES, PODRIAMOS VER SI EFECTIVAMENTE EL MODELO FUNCIONA CORRECTAMENTE O NO.

¿QUE PODRIAMOS HACER PARA ARREGLAR ESTO?

TENEMOS TRES POSIBLES SOLUCIONES:

1º- **AJUSTE DE PESOS EN EL MODELO:** APROVECHANDO QUE LA REGRESION LOGITICA PERMITE ASIGNAR DIFERENTES PESOS A LAS CLASES, PODRIAMOS DARLE MÁS PESO A LA CLASE POSITIVA (MINORITARIA) PARA QUE EL MODELO SE ENFOQUE MÁS EN PREDECIR ESTOS CASOS, HACIENDO QUE NO SE FAVOREZCA TANTO LA CLASE NEGATIVA (MAYORITARIA)

2º- **SUBMUESTREO O SOBREMUETREO:** OTRA POSIBLE SOLUCIÓN SERIA REDUCIR EL NUMERO DE CASOS NEGATIVOS O, POR EL CONTRARIO, AUMENTAR EL NUMERO DE CASOS POSITIVOS Y REPETIR EL ANÁLISIS

3º- **METRICAS ADICIONALES:** PODRIAMOS AÑADIR A NUESTRO MODELOS OTRAS METRICAS COMO RECALL, F1-SCORE, ETC YA QUE LA PRECISIÓN NO SIEMPRE VA A SER UN BUEN INDICATIVO, COMO HEMOS VISTO, DEL DESEMPEÑO.



VAMOS A APLICAR LA PRIMERA SOLUCION, QUE ES LA QUE MÁS FACIL NOS PERMITE R, PARA COMPROBAR SI NUESTRO MODELO MEJORA

## SOLUCION A NUESTRO MODELO


ES UN BUEN MOMENTO PARA EXPLICAR QUE, EN UN PRINCIPIO, LOS OUTLIERS NO ESTÁN AFECTANDO A NUESTROS MODELOS, ASI QUE VAMOS A PODER HACER ESTAS PRUEBAS CON CUALQUIERA DE LOS DOS.
```{r}
# Crear un vector de pesos donde asignamos más peso a la clase positiva
pesos <- ifelse(train_data$Heart_Disease == 1, 5, 1)  # Aquí el 5 es el peso para la clase positiva

# Ajustar el modelo logístico con pesos
modelo_logistico_3 <- train(Heart_Disease ~ ., data = train_data, method = "glm", 
                          family = "binomial", trControl = train_control, 
                          weights = pesos)

# Imprimir resultados de los modelos
print(modelo_logistico_3)
```
DE ACUERDO, SI BIEN ES CIERTO QUE EL ACCURACY HA BAJADO, EL VALOR DE KAPPA HA AUMENTADO CONSIDERABLEMENTE. EN ESTE CASO, LE HEMOS DADO UN VALOR DE 5 PARA AUMENTAR LA CLASE MINORITARIA, SI JUGAMOS CON EL PESO QUE LE DAMOS, PODRIAMOS LLEGAR A OBTENER MEJORES RESULTADOS. 



VAMOS A PONER PESOS DISTINTOS
```{r}
# Crear un vector de pesos donde asignamos más peso a la clase positiva
pesos <- ifelse(train_data$Heart_Disease == 1, 6, 1)  # Ponemos 6 en vez de 5

# Ajustar el modelo logístico con pesos
modelo_logistico_4 <- train(Heart_Disease ~ ., data = train_data, method = "glm", 
                          family = "binomial", trControl = train_control, 
                          weights = pesos)

# Imprimir resultados de los modelos
print(modelo_logistico_4)
```
VEMOS QUE AÑADIENDO MÁS PESO, KAPPA DISMINUYE, ESTO ES PROBABLE QUE SEA PORQUE PROPORCIONALMENTE AHORA ESTÁ SIENDO LA CLASE MAYORITARIA LA POSITIVA. 


PODEMOS CONCLUIR QUE EL MEJOR MODELO ES EL LOGISTICO_3. CON UN ACCURACY DE 0.84 Y UN VALOR KAPPA DE 0.28, QUE SI BIEN SIGUE SIN SER MUY ALTO, ES BASTANTE MEJOR QUE EL PRIMERO.


ESTE DATASET HA SIDO COGIDO DE KAGGLE, POR LO QUE YO SOLO DOY EXPLICACIÓN A LO QUE TENGO EN MIS MANOS.




